# Lucence理论分析

## 一、全文检索的基本原理

Lucene是一个高效的，基于java的全文检索库。

#### 全文检索：我们生活中总体分为两种结构化和非结构化两种。

##### 结构化数据：

​	具有固定格式或者有限长度的数据，比如数据库

##### 非结构化数据【全文数据】：

​	不定长或者不固定的数据，比如邮件、word等。

##### 非结构化和结构化：

​	基于两种的结构，比如xml/html，当根据需要可按结构化数据来处理

##### 根据数据分类，速索也可以分为两种：

- 对结构化数据速索：比如对于数据库的速索
- 非结构化数据的速索：比如数据库的grep

##### 对于非结构化数据对全文检索主要有两种方法：

- 一种是顺序扫描法

  - 一个文件一个文件的查找，缺点就是速度慢

  对于非结构化数据，可以提取出一部分用来创建索引，将非结构化数据中的一部分提取出来一部分，重新组织的这一部分就是索引。

以上的分析可以知道，全文速索的方式就是创建索引和使用索引【索引的速索】。

- 创建索引：将显示生活中所有结构化和非结构化数据提取信息，就是索引创建的过程。
- 速索索引：就是得到用户的查询请求，速索创建的索引，然后返回结果的过程。



问题：速索中存储的是什么？

​	   如何创建索引？

​	   怎样对索引进行速索？

# 二、索引究竟存储什么？？

**问题**：顺序索引慢

​	原因：由于我们想要速索的信息和非结构化的数据所存储的信息不一致。

- 非结构化数据存储的是每个文件包含那个字符串，文件--》字符串
- 我们需要求出的是那个文件有字符串，也就是从字符串---》文件

我们从字符串到文件是从文件到字符串的反向过程，**所以又叫反向索引**

左边为词典，右边为内容。每个字符串都指向文档的列表，此文档链表为**倒排表**

​	以上方式我们提供索引就可以加快查找的速度。

以以下案例为例：

​	1.取出包含字符串的文档链表。

​	2.取出包含字符串的文档链表。

​	3.通过合并链表

------------------------

​	以上的方式，数据量比较少的时候就造成了，索引比顺序慢，数据量大的时候创建索引更慢，但是创建索引的速度会变得非常的慢，不过它仅仅是执行一次，有一劳永逸的效果。顺序索引会每次都会去重新扫描。

# 三、如何创建索引

全文检索一般有以下步骤：

- 第一步：一些要创建索引的原文档

  - 为了方便说明索引创建的过程，以案例为例：

- 第二步：将原文档传给分词组件

  - 分词组件会有以下几件事情
    - 将文档分为一个一个单独的单词，或者是词组。
    - 去除标点符号
    - 去除停顿词
  - 上面处理过后的就是词元

- 第三步：将得到的词元传给语言处理组件

  语言组件会对词元进行处理，比如对于英文进行如下处理：

  ​	单词变小写。

  ​	将单词变为词根

  ​		单词缩写为词根：stemming

  ​		单词变为词根：Iemmatization

  - 二者的异同

    - 两个都是将单词变为词根
    - stramming采用的是“缩减”的方式，Iemmatization使用的是变换的方式
    - stramming采用某种固定的算法来做缩减，Iemmatization使用字典来进行转变
    - 二者不是互斥，而是有交集

    上述数据处理之后，就变为了词（Term）

- 第四步将词传输给索引组件

  - 利用得到的词创建一个字典，然后对字典进行排序

  - 将合并相同的词成为文档倒排链表。

    - 链表的含义:文档频率和词频率

      文档频率：有多少个文档包含这个词

      词频率：此文件中有多少个词

      标的格式也就是

      ​	词    文档1---频率   文档2---频率

- 如何对索引进行速索

  - 上面的操作就可以查找文档的数据了，但是数据文件并不是一个或者十个，我们怎样将最终的几个放在最前面呢，文档中包含数据的是文件可以是几千个或者是几万个。所以查找的文档中数据的相关性也是一个主要的问题。

    - 第一步：用户输入查询语句输入查询的语句，比如and  or  NOT等

    - 第二步：对查询语句进行分析对查询语句进行词分析

      - 词法分析主要用来识别单词和关键字
      - 词法分析主要根据查询语法形成一个语法树

    - 第三步：速索索引，得到符合语法树的文档

      - 首先找到包含关键词的文档
      - 对包含关键词的链表进行合并操作，得到包含所需关键字的链表，如果有非操作，那么就会将不符合条件的去除掉。
      - 所查找的就是我们要找的文档。

    - 第四步：根据得到的文档和查询语句的相关性，对结果进行排序

      - 查出的数据应该相关性高的放在前面

        - 如何打分，那就是计算权重

          一个词中数据的重要性，一般有两个因素

          文档中的词频 ：词频越高，说明他就越重要

          多少文档包含关键词，数值越大，说明越不重要。

        ----

        因为词出现的越多越重要，但是有的词就是会出现很多，这个时候也不能说他就越重要，这个时候需要查看的是是不有越多的文档含有这个词，如果说此越多，那么就说明越不重要。




----

​	我现在的认识就是：我们在查询文档输入关键字的时候，会将文档进行遍历，并且将关键字去出来形成一个索引表，当我们去查找的时候，根据词法将其进行分析，在将分析的数据去查找索引，对其相关性进行排序。

	# 总结:

​	1.索引创建

​	  （1）有一系列被索引的文件

​	  （2）被索引的文件经过词法分析和语言处理形成一系列次。

​	  （3）经过索引创建形成词典和反向索引表

​	  （4）将所有存入磁盘

​	2.速索过程

​	  （1）输入查询语句

   	  （2）对查询的语句经过语法分析和语言分析得到一系列词

​	  （3）经过词法分析得到一个词法树

​	  （4）通过索引存储读入内存

​	  （5）利用查询书速索索引，从而得到每个词的文档表，对其进行交差

​	  （6）将文档进行排序

​	  （7）返回查询结果给用户	

